# OPEA Highlight
* Enable Dataprep with llamaIndex, PGvector and RAGAS
* LLM MicroService supports vLLM and RayServe

# GenAIExamples 
* ChatQnA
** ChatQnA supports Qwen2  ([422b4b](https://github.com/opea-project/GenAIExamples/commit/422b4bc56b4e5500538b3d75209320d0a415483b))
** Add no_proxy in docker compose yaml for micro services ([99eb6a](https://github.com/opea-project/GenAIExamples/commit/99eb6a6a7eab4a6d24cbb47d4a541ff4aef41b57), [240587](https://github.com/opea-project/GenAIExamples/commit/240587932b04adeaf740d70229dd27ebd42d5dcd))
 
# GenAIComps 

# GenAIEvals 

# GenAIInfra 
